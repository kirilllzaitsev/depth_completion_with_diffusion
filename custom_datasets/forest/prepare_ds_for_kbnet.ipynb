{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kirilllzaitsev/calibrated-backprojection-network\n",
    "!cd calibrated-backprojection-network && pip install . && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from kbnet import data_utils\n",
    "import yaml\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_prep_in_kbnet_format = True\n",
    "do_crop=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_rosbag_path=\"./kirill_data_test.bag\"\n",
    "\n",
    "if do_prep_in_kbnet_format:\n",
    "    base_output_dir='./kbnet_format_subsample'\n",
    "else:\n",
    "    base_output_dir='./kitti_format_subsample'\n",
    "base_data_dir=\"./data/camera/point_cloud_colorizer_ros/depth_image_camera_2\"\n",
    "\n",
    "validity_map_dir=f\"{base_output_dir}/validity_map\"\n",
    "img_dir=f\"{base_output_dir}/image\"\n",
    "cam_dir=f\"{base_output_dir}/intrinsics\"\n",
    "paths_dir=f\"{base_output_dir}/paths\"\n",
    "depth_output_dir=f'{base_output_dir}/sparse_depth'\n",
    "for dir in [validity_map_dir, img_dir, cam_dir, paths_dir, depth_output_dir]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag(subsample_rosbag_path)\n",
    "info_dict = yaml.safe_load(bag._get_yaml_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './kirill_data_test.bag',\n",
       " 'version': 2.0,\n",
       " 'duration': 1600.432037,\n",
       " 'start': 1680764280.802401,\n",
       " 'end': 1680765881.234438,\n",
       " 'size': 21148188278,\n",
       " 'messages': 15724,\n",
       " 'indexed': True,\n",
       " 'compression': 'lz4',\n",
       " 'uncompressed': 97817475536,\n",
       " 'compressed': 21144547291,\n",
       " 'types': [{'type': 'sensor_msgs/Image',\n",
       "   'md5': '060021388200f6f0f447d0fcd9c64743'}],\n",
       " 'topics': [{'topic': '/point_cloud_colorizer_ros/depth_image_camera_2',\n",
       "   'type': 'sensor_msgs/Image',\n",
       "   'messages': 7862,\n",
       "   'frequency': 5.0019},\n",
       "  {'topic': '/point_cloud_colorizer_ros/point_cloud_overlaid_camera_2',\n",
       "   'type': 'sensor_msgs/Image',\n",
       "   'messages': 7862,\n",
       "   'frequency': 5.0018}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dm_topic, image_topic = [\n",
    "    \"/point_cloud_colorizer_ros/depth_image_camera_2\",\n",
    "    \"/point_cloud_colorizer_ros/point_cloud_overlaid_camera_2\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "from attr import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RosbagSample:\n",
    "    topic: str\n",
    "    msg: t.Any\n",
    "    ts: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_sample_raw = next(iter(bag.read_messages(topics=[sparse_dm_topic])))\n",
    "bag_sample = RosbagSample(*bag_sample_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/media/master/wext/cv_data/sensor_data/forest/subsample/first_5_minute_compressed.bag',\n",
       " 'version': 2.0,\n",
       " 'duration': 329.9856,\n",
       " 'start': 1680764280.802401,\n",
       " 'end': 1680764610.788001,\n",
       " 'size': 21487811932,\n",
       " 'messages': 3454,\n",
       " 'indexed': True,\n",
       " 'compression': 'none',\n",
       " 'types': [{'type': 'sensor_msgs/Image',\n",
       "   'md5': '060021388200f6f0f447d0fcd9c64743'}],\n",
       " 'topics': [{'topic': '/point_cloud_colorizer_ros/depth_image_camera_2',\n",
       "   'type': 'sensor_msgs/Image',\n",
       "   'messages': 1727,\n",
       "   'frequency': 5.0108},\n",
       "  {'topic': '/point_cloud_colorizer_ros/point_cloud_overlaid_camera_2',\n",
       "   'type': 'sensor_msgs/Image',\n",
       "   'messages': 1727,\n",
       "   'frequency': 5.0076}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values_to_different_range(value, leftMin, leftMax, rightMin, rightMax):\n",
    "    # Figure out how 'wide' each range is\n",
    "    leftSpan = leftMax - leftMin\n",
    "    rightSpan = rightMax - rightMin\n",
    "\n",
    "    # Convert the left range into a 0-1 range (float)\n",
    "    valueScaled = (value - leftMin) / float(leftSpan)\n",
    "\n",
    "    # Convert the 0-1 range into a value in the right range.\n",
    "    return rightMin + (valueScaled * rightSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:30<00:00, 32.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "forest_max_depth = 40\n",
    "kitti_max_depth = 80\n",
    "\n",
    "total = 1000\n",
    "for index, (bag_sample) in tqdm(\n",
    "    enumerate(bag.read_messages(topics=[sparse_dm_topic])),\n",
    "    total=total,\n",
    "):\n",
    "    if index >= total:\n",
    "        break\n",
    "    bag_sample = RosbagSample(*bag_sample)\n",
    "    im=(np.frombuffer(bag_sample.msg.data, np.float32)).reshape(bag_sample.msg.height, bag_sample.msg.width, -1)\n",
    "    time_str = f\"{bag_sample.msg.header.stamp.to_sec():.6f}\"\n",
    "    filename = f\"{time_str[0:18]}.png\"\n",
    "    output_img_path = f\"{depth_output_dir}/{filename}\"\n",
    "    dm = im[:,:,0]\n",
    "    if do_crop:\n",
    "        dm=dm[300:300+352,100:100+1216]\n",
    "    dm=map_values_to_different_range(dm, 0, forest_max_depth, 0, kitti_max_depth)\n",
    "    data_utils.save_depth(dm, output_img_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VALIDITY MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for path in Path(base_data_dir).iterdir():\n",
    "    _, validity_map = data_utils.load_depth_with_validity_map(path)\n",
    "\n",
    "    validity_map_output_path=f\"{validity_map_dir}/{path.name}\"\n",
    "    data_utils.save_validity_map(validity_map, validity_map_output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [02:23,  6.98it/s]                          \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "base_data_dir=\"./data/camera/point_cloud_colorizer_ros/point_cloud_overlaid_camera_2\"\n",
    "\n",
    "for path in tqdm(Path(base_data_dir).iterdir(), total=total):\n",
    "    image = cv2.imread(str(path))\n",
    "    if do_crop:\n",
    "        image=image[300:300+352,100:100+1216,:]\n",
    "    if do_prep_in_kbnet_format:\n",
    "        image = np.concatenate([image, image, image], axis=1)\n",
    "    cv2.imwrite(f\"{img_dir}/{path.name}\", image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRINSICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cam_info = pd.read_csv(\"./alphasense_driver_ros-cam4-color-camera_info.csv\")\n",
    "K_idx_range=cam_info.columns.to_list().index(\"K_0\"), cam_info.columns.to_list().index(\"K_8\")\n",
    "P_idx_range=cam_info.columns.to_list().index(\"P_0\"), cam_info.columns.to_list().index(\"P_11\")\n",
    "R_idx_range=cam_info.columns.to_list().index(\"R_0\"), cam_info.columns.to_list().index(\"R_8\")\n",
    "num_subsamples = 974\n",
    "subsample = cam_info[cam_info[\"header.frame_id\"].str.contains(\"cam4\")].iloc[:num_subsamples]\n",
    "filenames = subsample.Time.apply(\n",
    "    lambda time_str: f\"{str(time_str)[0:18]}\"\n",
    ")\n",
    "\n",
    "intrinsics = subsample.iloc[:,K_idx_range[0]:K_idx_range[1]+1].values.reshape(-1, 3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we will take the center crop of the images during augmentation\n",
    "# that changes the optical centers, but not focal lengths\n",
    "if do_crop:\n",
    "    orig_size=(1440, 1080)\n",
    "    # orig_size=(1242, 375)\n",
    "    new_size=(1216, 352)\n",
    "    intrinsics[:, 0, 2] = (\n",
    "        intrinsics[:, 0, 2] - abs(orig_size[0]-new_size[0])/2\n",
    "    )\n",
    "    intrinsics[:, 1, 2] = (\n",
    "        intrinsics[:, 1, 2] - abs(orig_size[1]-new_size[1])/2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "974it [00:00, 4504.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for path, intrinsic in tqdm(zip(filenames, intrinsics)):\n",
    "    full_path = f\"{cam_dir}/{path}.npy\"\n",
    "    np.save(full_path, intrinsic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORM PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for entity in [\"sparse_depth\", \"validity_map\", \"image\", \"intrinsics\"]:\n",
    "    base_data_dir=f\"{base_output_dir}/{entity}\"\n",
    "    with open(f\"{paths_dir}/{entity}.txt\", \"w\") as f:\n",
    "        for path in Path(base_data_dir).iterdir():\n",
    "            entity_output_path=f\"{base_output_dir}/{entity}/{path.name}\"\n",
    "            f.write(f\"{entity_output_path}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26a37d813e3bf13d3b2127494e56cc647059c9275c4b9fcd26dbdbfe53214b20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
