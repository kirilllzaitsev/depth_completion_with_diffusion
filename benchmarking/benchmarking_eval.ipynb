{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 10:25:37.847813: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 10:25:37.921983: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-20 10:25:38.296760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/master/.conda/envs/ssdc/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-20 10:25:38.296822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/master/.conda/envs/ssdc/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-20 10:25:38.296826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from rsl_depth_completion.data.components.raw_data_loaders import depth_read, img_read\n",
    "from kbnet import eval_utils\n",
    "import yaml\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_config = yaml.safe_load(open(\"common.yaml\"))\n",
    "split = common_config[\"split\"]\n",
    "config = {**common_config}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_input_img = Path(config[\"path_to_input_img\"])\n",
    "path_to_sparse_dm = Path(config[\"path_to_sparse_dm\"])\n",
    "path_to_gt = Path(config[\"path_to_gt\"])\n",
    "\n",
    "mask_result_dir = config[\"mask_dir\"]\n",
    "masked_img_names = [\n",
    "    x[x.rfind(\"/\") + 1 :]\n",
    "    for x in open(config[\"image_filelist_path\"]).read().splitlines()\n",
    "]\n",
    "mask_result_dir = Path(mask_result_dir)\n",
    "# all masks, but inference was interrupted and not all outputs are available\n",
    "assert len(masked_img_names) >= len(os.listdir(path_to_input_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 10:25:41.293219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:41.309050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:41.309207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:41.309776: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 10:25:41.310523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:41.310630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:41.310704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:42.319154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:42.319290: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:42.319359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 10:25:42.319424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5621 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ts = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "img2class_logdir = f\"tb_logs/masked_predictions/{split}/img2class_\" + ts\n",
    "class2img_logdir = f\"tb_logs/masked_predictions/{split}/class2img_\" + ts\n",
    "# !rm -rf tb_logs\n",
    "img2class_file_writer = tf.summary.create_file_writer(img2class_logdir)\n",
    "class2img_file_writer = tf.summary.create_file_writer(class2img_logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "model_names = [\"kbnet\", \"penet\", \"nlspn\"]\n",
    "\n",
    "errors_per_class = defaultdict(\n",
    "    lambda: {\n",
    "        \"metrics\": {\n",
    "            \"rmse\": {k: 0.0 for k in model_names},\n",
    "            \"mae\": {k: 0.0 for k in model_names},\n",
    "        },\n",
    "        \"count\": 0,\n",
    "        \"imgs_with_no_gt\": [],\n",
    "        \"imgs_with_no_prediction\": {k: [] for k in model_names},\n",
    "    }\n",
    ")\n",
    "errors_per_img = defaultdict(\n",
    "    lambda: {\n",
    "        \"metrics\": {\n",
    "            \"rmse\": {k: 0.0 for k in model_names},\n",
    "            \"mae\": {k: 0.0 for k in model_names},\n",
    "        },\n",
    "        \"num_objects\": 0,\n",
    "        \"objects\": [],\n",
    "        \"masks_with_no_gt\": [],\n",
    "        \"masks_with_no_prediction\": {k: [] for k in model_names},\n",
    "    }\n",
    ")\n",
    "fig_classes = defaultdict(list)\n",
    "n_first_imgs_to_consider=300\n",
    "input_img_names = sorted(os.listdir(path_to_input_img))[:n_first_imgs_to_consider]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_consider = [\n",
    "    # smooth surfaces\n",
    "    \"road\",\n",
    "    \"wall\",\n",
    "    \"terrain\",\n",
    "    # rough surfaces\n",
    "    \"vegetation\",\n",
    "    # objects with sharp edges & small objects\n",
    "    \"pole\",\n",
    "    \"person\",\n",
    "    \"rider\",\n",
    "    # objects with holes\n",
    "    \"bicycle\",\n",
    "]\n",
    "pixels_per_class = defaultdict(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:11<01:50,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: rider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:29<01:22,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n",
      "No GT depth values for the class: rider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:47<01:01,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: terrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:50<00:56,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [01:05<00:45,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [01:20<00:30,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [01:34<00:14,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:47<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# n_imgs_to_evaluate = 0\n",
    "n_imgs_to_evaluate = 30\n",
    "\n",
    "# predicted_dm_scaler = 1000.0\n",
    "predicted_dm_scaler = 1.0\n",
    "\n",
    "img_idxs = np.random.choice(len(input_img_names), n_imgs_to_evaluate, replace=False)\n",
    "\n",
    "with img2class_file_writer.as_default():\n",
    "    for counter, img_idx in tqdm(enumerate(img_idxs), total=n_imgs_to_evaluate):\n",
    "        img_name = input_img_names[img_idx]\n",
    "        img_name = img_name.replace(\".png\", \"\")\n",
    "        img_name_in_index_format = f\"{img_idx:010d}\"\n",
    "\n",
    "        masked_img_name_idx = masked_img_names.index(f\"{img_name}.png\")\n",
    "        if masked_img_name_idx == -1:\n",
    "            print(f\"Skipping {img_name} as it has no segmentation masks.\")\n",
    "            continue\n",
    "        masked_img_name = masked_img_names[masked_img_name_idx]\n",
    "\n",
    "        sparse_dm = depth_read(\n",
    "            path_to_sparse_dm\n",
    "            / f\"{img_name}.png\".replace(\"_image_\", \"_velodyne_raw_\", 1)\n",
    "        ).squeeze()\n",
    "        gt_dm = depth_read(\n",
    "            path_to_gt / f\"{img_name}.png\".replace(\"_image_\", \"_groundtruth_depth_\", 1)\n",
    "        ).squeeze()\n",
    "        img = img_read(path_to_input_img / f\"{img_name}.png\")\n",
    "\n",
    "        pred_dms = []\n",
    "        are_all_preds_loaded = True\n",
    "        for model_name in model_names:\n",
    "            model_config = yaml.safe_load(open(f\"{model_name}_val.yaml\"))\n",
    "            path_to_result_dir = Path(model_config[\"result_dir\"])\n",
    "            path_to_pred_dm = Path(path_to_result_dir)\n",
    "\n",
    "            try:\n",
    "                pred_dm = depth_read(\n",
    "                    path_to_pred_dm / f\"{img_name_in_index_format}.png\"\n",
    "                ).squeeze()\n",
    "            except OSError as e:\n",
    "                print(f\"{model_name} prediction for {img_name} is unavailable due to:\\n{e}\")\n",
    "                errors_per_class[model_name][\"imgs_with_no_prediction\"].append(img_name)\n",
    "                errors_per_img[model_name][\"masks_with_no_prediction\"].append(\n",
    "                    masked_img_name\n",
    "                )\n",
    "                are_all_preds_loaded = False\n",
    "                break\n",
    "            pred_dms.append(pred_dm)\n",
    "            \n",
    "        if not are_all_preds_loaded:\n",
    "            print(f\"Skipping {img_name} as not all predictions are available.\")\n",
    "            continue\n",
    "\n",
    "        num_objects = 0\n",
    "        figs_masked = []\n",
    "        figs_full = []\n",
    "\n",
    "        fig = utils.plot_full_results_for_all_models(\n",
    "            model_names,\n",
    "            pred_dms,\n",
    "            img,\n",
    "            title=f\"{img_name}\",\n",
    "            save_path=\"./test_full.png\",\n",
    "        )\n",
    "        fig_full = utils.plot_to_image(fig)\n",
    "        figs_full.append(fig_full)\n",
    "\n",
    "        for obj_class_with_ext in tqdm(\n",
    "            os.listdir(mask_result_dir / masked_img_name), leave=False\n",
    "        ):\n",
    "            obj_class = obj_class_with_ext.split(\".\")[0]\n",
    "            if obj_class not in objects_to_consider:\n",
    "                continue\n",
    "            binary_mask = (\n",
    "                cv2.imread(\n",
    "                    str(mask_result_dir / masked_img_name / obj_class_with_ext),\n",
    "                    cv2.IMREAD_GRAYSCALE,\n",
    "                )\n",
    "                / 255\n",
    "            )\n",
    "            gt_dm_masked = gt_dm * binary_mask\n",
    "            if len(np.nonzero(gt_dm_masked)[0]) == 0:\n",
    "                print(f\"No GT depth values for the class: {obj_class}\")\n",
    "                errors_per_class[obj_class][\"imgs_with_no_gt\"].append(img_name)\n",
    "                errors_per_img[img_name][\"masks_with_no_gt\"].append(obj_class)\n",
    "                continue\n",
    "\n",
    "            for model_name, pred_dm in zip(model_names, pred_dms):\n",
    "                pred_dm_masked = pred_dm * binary_mask\n",
    "\n",
    "                mae = eval_utils.mean_abs_err(\n",
    "                    predicted_dm_scaler * pred_dm_masked, predicted_dm_scaler * gt_dm_masked\n",
    "                )\n",
    "                rmse = eval_utils.root_mean_sq_err(\n",
    "                    predicted_dm_scaler * pred_dm_masked, predicted_dm_scaler * gt_dm_masked\n",
    "                )\n",
    "\n",
    "                if len(np.nonzero(pred_dm_masked)[0]) == 0:\n",
    "                    errors_per_img[img_name][\"masks_with_no_prediction\"][\n",
    "                        model_name\n",
    "                    ].append(obj_class)\n",
    "                    errors_per_class[obj_class][\"imgs_with_no_prediction\"][\n",
    "                        model_name\n",
    "                    ].append(img_name)\n",
    "\n",
    "                errors_per_class[obj_class][\"metrics\"][\"rmse\"][\n",
    "                    model_name\n",
    "                ] += rmse\n",
    "                errors_per_class[obj_class][\"metrics\"][\"mae\"][model_name] += mae\n",
    "\n",
    "                errors_per_img[img_name][\"metrics\"][\"rmse\"][model_name] += rmse\n",
    "                errors_per_img[img_name][\"metrics\"][\"mae\"][model_name] += mae\n",
    "\n",
    "            num_pixels = len(np.nonzero(binary_mask)[0])\n",
    "            pixels_per_class[obj_class] += num_pixels\n",
    "\n",
    "            errors_per_class[obj_class][\"count\"] += 1\n",
    "            errors_per_img[img_name][\"num_objects\"] += 1\n",
    "            errors_per_img[img_name][\"objects\"].append(obj_class)\n",
    "\n",
    "            fig = utils.plot_masked_results_for_all_models(\n",
    "                model_names,\n",
    "                pred_dms,\n",
    "                img,\n",
    "                binary_mask,\n",
    "                obj_class,\n",
    "                title=f\"{obj_class}-{img_name}\",\n",
    "                save_path=\"./test_masked.png\",\n",
    "            )\n",
    "            fig_masked = utils.plot_to_image(fig)\n",
    "\n",
    "            figs_masked.append(fig_masked)\n",
    "            fig_classes[obj_class].append(fig_masked)\n",
    "            # break\n",
    "\n",
    "        utils.log_imgs(f\"{img_name}/masked\", figs_masked)\n",
    "        utils.log_imgs(f\"{img_name}/full\", figs_full)\n",
    "        tb_name_prefix = f\"{img_name}\"\n",
    "        utils.log_errors_per_img(errors_per_img, img_name, tb_name_prefix, model_names)\n",
    "\n",
    "        if counter >= n_imgs_to_evaluate:\n",
    "            break\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with class2img_file_writer.as_default():\n",
    "    for obj_class, figs in fig_classes.items():\n",
    "        utils.log_imgs(f\"{obj_class}/imgs\", figs)\n",
    "        utils.log_errors_per_class(errors_per_class, obj_class, model_names)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about the results:\n",
    "\n",
    "- mean pixel error is in micrometers\n",
    "- for some images, no ground truth available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kbnet</th>\n",
       "      <th>penet</th>\n",
       "      <th>nlspn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(terrain, 35.789)</td>\n",
       "      <td>(terrain, 36.022)</td>\n",
       "      <td>(terrain, 35.946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(wall, 56.912)</td>\n",
       "      <td>(wall, 56.996)</td>\n",
       "      <td>(wall, 57.024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(pole, 70.545)</td>\n",
       "      <td>(pole, 61.905)</td>\n",
       "      <td>(pole, 61.264)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(road, 30.291)</td>\n",
       "      <td>(road, 30.377)</td>\n",
       "      <td>(road, 30.386)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(bicycle, 22.956)</td>\n",
       "      <td>(bicycle, 23.047)</td>\n",
       "      <td>(bicycle, 22.96)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(rider, 27.442)</td>\n",
       "      <td>(rider, 27.399)</td>\n",
       "      <td>(rider, 27.34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(vegetation, 118.554)</td>\n",
       "      <td>(vegetation, 82.059)</td>\n",
       "      <td>(vegetation, 89.168)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(person, 55.708)</td>\n",
       "      <td>(person, 56.232)</td>\n",
       "      <td>(person, 56.067)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   kbnet                 penet                 nlspn\n",
       "0      (terrain, 35.789)     (terrain, 36.022)     (terrain, 35.946)\n",
       "1         (wall, 56.912)        (wall, 56.996)        (wall, 57.024)\n",
       "2         (pole, 70.545)        (pole, 61.905)        (pole, 61.264)\n",
       "3         (road, 30.291)        (road, 30.377)        (road, 30.386)\n",
       "4      (bicycle, 22.956)     (bicycle, 23.047)      (bicycle, 22.96)\n",
       "5        (rider, 27.442)       (rider, 27.399)        (rider, 27.34)\n",
       "6  (vegetation, 118.554)  (vegetation, 82.059)  (vegetation, 89.168)\n",
       "7       (person, 55.708)      (person, 56.232)      (person, 56.067)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mae_per_category = {}\n",
    "model_mae_per_category_unsorted = {}\n",
    "for model_name in model_names:\n",
    "    model_errors = {}\n",
    "    for cat, cat_stats in errors_per_class.items():\n",
    "        model_errors[cat] = round((\n",
    "            cat_stats[\"metrics\"][\"mae\"][model_name] / pixels_per_class[cat]\n",
    "        ) * 1e6, 3)\n",
    "    model_mae_per_category[model_name] = sorted(\n",
    "        model_errors.items(), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    model_mae_per_category_unsorted[model_name] = model_errors.items()\n",
    "pd.DataFrame(model_mae_per_category_unsorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_mae_per_category).to_csv(\"model_mae_per_category.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for writer in [img2class_file_writer, class2img_file_writer]:\n",
    "    with writer.as_default():\n",
    "        for model_name in model_names:\n",
    "            model_config = yaml.safe_load(open(f\"{model_name}_val.yaml\"))\n",
    "            path_to_result_dir = model_config[\"result_dir\"]\n",
    "            tf.summary.text(\n",
    "                f\"meta/{model_name}/result_dir\",\n",
    "                str(path_to_result_dir),\n",
    "                step=0,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad1db80ca9b36dd5ac1f394e7b9b19f6166d1645d5a0e339bf524a97ebc784e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
