{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 18:17:50.099647: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 18:17:50.184103: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-27 18:17:50.564531: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/master/.conda/envs/ssdc/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-27 18:17:50.564569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/master/.conda/envs/ssdc/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-27 18:17:50.564572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from rsl_depth_completion.data.components.raw_data_loaders import depth_read, img_read\n",
    "from kbnet import eval_utils\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from kbnet import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_config = yaml.safe_load(open(\"common.yaml\"))\n",
    "split = common_config[\"split\"]\n",
    "config = {**common_config}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_input_img = Path(config[\"path_to_input_img\"])\n",
    "path_to_sparse_dm = Path(config[\"path_to_sparse_dm\"])\n",
    "path_to_gt = Path(config[\"path_to_gt\"])\n",
    "\n",
    "mask_result_dir = config[\"mask_dir\"]\n",
    "masked_img_names = [\n",
    "    x[x.rfind(\"/\") + 1 :]\n",
    "    for x in open(config[\"image_filelist_path\"]).read().splitlines()\n",
    "]\n",
    "mask_result_dir = Path(mask_result_dir)\n",
    "# all masks, but inference was interrupted and not all outputs are available\n",
    "assert len(masked_img_names) >= len(os.listdir(path_to_input_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 18:17:52.814052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:52.881081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:52.881319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:52.882171: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 18:17:52.883295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:52.883456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:52.883661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:54.067413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:54.067682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:54.067753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 18:17:54.067822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5713 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# create_new_log_dir = True\n",
    "create_new_log_dir = False\n",
    "if create_new_log_dir:\n",
    "    ts = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    img2class_logdir = f\"tb_logs/masked_predictions/{split}/img2class_\" + ts\n",
    "    class2img_logdir = f\"tb_logs/masked_predictions/{split}/class2img_\" + ts\n",
    "    # !rm -rf tb_logs\n",
    "else:\n",
    "    img2class_logdir = \"tb_logs/masked_predictions/val/img2class_overall\"\n",
    "    class2img_logdir = \"tb_logs/masked_predictions/val/class2img_overall\"\n",
    "img2class_file_writer = tf.summary.create_file_writer(img2class_logdir)\n",
    "class2img_file_writer = tf.summary.create_file_writer(class2img_logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_consider = [\n",
    "    # smooth surfaces\n",
    "    \"road\",\n",
    "    \"wall\",\n",
    "    \"terrain\",\n",
    "    # rough surfaces\n",
    "    \"vegetation\",\n",
    "    # objects with sharp edges & small objects\n",
    "    \"pole\",\n",
    "    \"person\",\n",
    "    \"rider\",\n",
    "    # objects with holes\n",
    "    \"bicycle\",\n",
    "]\n",
    "pixels_per_class = defaultdict(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_names = [\"kbnet\", \"penet\", \"nlspn\"]\n",
    "n_first_imgs_to_consider=300\n",
    "input_img_names = sorted(os.listdir(path_to_input_img))[:n_first_imgs_to_consider]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "errors_per_class = defaultdict(\n",
    "    lambda: {\n",
    "        \"metrics\": {\n",
    "            \"rmse\": {k: 0.0 for k in model_names},\n",
    "            \"mae\": {k: 0.0 for k in model_names},\n",
    "        },\n",
    "        \"count\": 0,\n",
    "        \"imgs_with_no_gt\": [],\n",
    "        \"imgs_with_no_prediction\": {k: [] for k in model_names},\n",
    "    }\n",
    ")\n",
    "errors_per_img = defaultdict(\n",
    "    lambda: {\n",
    "        \"metrics\": {\n",
    "            \"rmse\": {k: 0.0 for k in model_names},\n",
    "            \"mae\": {k: 0.0 for k in model_names},\n",
    "        },\n",
    "        \"num_objects\": 0,\n",
    "        \"objects\": [],\n",
    "        \"masks_with_no_gt\": [],\n",
    "        \"masks_with_no_prediction\": {k: [] for k in model_names},\n",
    "    }\n",
    ")\n",
    "fig_classes = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs_to_evaluate = 50\n",
    "img_idxs = np.random.choice(len(input_img_names), n_imgs_to_evaluate, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47112db83124e65ad163c662b3b7723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/master/wext/cv_data/result_postprocessing/utils.py:118: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e0bc74dae24adc8946e46a44d21e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667d370e8eea47089c3cdcda9339fd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: wall\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ebe16bf37244ef9d9a95153e556653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618a3e600587487e8c88c1eb4f5ba0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fe9aa2a2764ad7ae28478d0c0dc65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a772f20654734b12a9a959eaef05b73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a51cd439f640b9b1fce50103ee969f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f837f7944b3b4579bed5d13576a8f40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee424fb6f17f448d801641adee120ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73c51f7acd342f7b990fc60e1144f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a482414e3e64d128995585801409cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7cab03d5164986ad53fd5409c89a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67f490649c14cfdb221adaf1b06012c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb273bc82764b5b944c2aae110f9f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: wall\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe422dc0c05f4f8b9385c46e4a9a1f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1375b4c7fe3450d9357993eede19e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57c01bd6ea7410ca7d0e63881e1f370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63accb841e8b4acda373cc28910f3ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcbce3968e34174be30895270810f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6edd26719d4eb584f53976b22e4584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4056807941dc47fb8519737813d5049a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43ab277d2c545d2b74546f137fa521a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d25207048b14b07a8aaca6641e95d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc711c142574a9eb81823cd4c72457b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f990174f8ea542d9874f0c96e2a607de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8f615fb06d408aafb63fb36a11195f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: person\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e76e31337c4d269ff5c52115b07346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ef331c88424002af88a7be0d0ff2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: terrain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5036828bb649c3af0daa8328f41ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33640b1acd904033bac5fe2781fbc3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: bicycle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1cbd11d7444183bb3930a75488689d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cabaac1e034999bdd2f41592b93ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4665ceaa9948a397dccc45a11a8000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2e964541da442ebedee5c38574557a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ef14d9d3f04120aec645a97c02cf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: terrain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80092ce6cdd8485fb9eb3024e17a06dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b21509de704477482a3d5701208c201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: bicycle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411e38cc68b240ac958fb04ada205ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beddc3e664614f418bd9ec0768b48b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d35a6049ad4e05a981b07c1444669a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0319c6db5e4dca92a9692bdfc36145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e7e4d617cd4c76b82413607b0f5ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81be42a447b4f79979eaa1882a7d276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8a264f9ba94ea2a9a67186cd2d3f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab2b8dd32be42c293a6fc72fb7aaf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GT depth values for the class: rider\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f573bf82b3431ebdcc958dc5b039a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3350205d9854e9e951f098fc8823a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74994714f57741c7b48cbadc9f5299fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3481c3b0794be0a3bee4769534564d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372c275c165a4b26a70f25f506a5ec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predicted_dm_scaler = 1000.0\n",
    "predicted_dm_scaler = 1.0\n",
    "\n",
    "\n",
    "with img2class_file_writer.as_default():\n",
    "    for counter, img_idx in tqdm(enumerate(img_idxs), total=n_imgs_to_evaluate):\n",
    "        img_name = input_img_names[img_idx]\n",
    "        img_name = img_name.replace(\".png\", \"\")\n",
    "        img_name_in_index_format = f\"{img_idx:010d}\"\n",
    "\n",
    "        masked_img_name_idx = masked_img_names.index(f\"{img_name}.png\")\n",
    "        if masked_img_name_idx == -1:\n",
    "            print(f\"Skipping {img_name} as it has no segmentation masks.\")\n",
    "            continue\n",
    "        masked_img_name = masked_img_names[masked_img_name_idx]\n",
    "\n",
    "        sparse_dm = depth_read(\n",
    "            path_to_sparse_dm\n",
    "            / f\"{img_name}.png\".replace(\"_image_\", \"_velodyne_raw_\", 1)\n",
    "        ).squeeze()\n",
    "        gt_dm, validity_map = data_utils.load_depth_with_validity_map(\n",
    "            path_to_gt / f\"{img_name}.png\".replace(\"_image_\", \"_groundtruth_depth_\", 1)\n",
    "        )\n",
    "        img = img_read(path_to_input_img / f\"{img_name}.png\")\n",
    "\n",
    "        pred_dms = []\n",
    "        are_all_preds_loaded = True\n",
    "        for model_name in model_names:\n",
    "            model_config = yaml.safe_load(open(f\"{model_name}_val.yaml\"))\n",
    "            path_to_result_dir = Path(model_config[\"result_dir\"])\n",
    "            path_to_pred_dm = Path(path_to_result_dir)\n",
    "\n",
    "            try:\n",
    "                pred_dm = depth_read(\n",
    "                    path_to_pred_dm / f\"{img_name_in_index_format}.png\"\n",
    "                ).squeeze()\n",
    "            except OSError as e:\n",
    "                print(\n",
    "                    f\"{model_name} prediction for {img_name} is unavailable due to:\\n{e}\"\n",
    "                )\n",
    "                errors_per_class[model_name][\"imgs_with_no_prediction\"][\n",
    "                    model_name\n",
    "                ].append(img_name)\n",
    "                errors_per_img[model_name][\"masks_with_no_prediction\"][\n",
    "                    model_name\n",
    "                ].append(masked_img_name)\n",
    "                are_all_preds_loaded = False\n",
    "                break\n",
    "            pred_dms.append(pred_dm)\n",
    "\n",
    "        if not are_all_preds_loaded:\n",
    "            print(f\"Skipping {img_name} as not all predictions are available.\")\n",
    "            continue\n",
    "\n",
    "        num_objects = 0\n",
    "        figs_masked = []\n",
    "        figs_full = []\n",
    "\n",
    "        fig = utils.plot_full_results_for_all_models(\n",
    "            model_names,\n",
    "            pred_dms,\n",
    "            img,\n",
    "            title=f\"{img_name}\",\n",
    "        )\n",
    "        fig_full = utils.plot_to_image(fig)\n",
    "        figs_full.append(fig_full)\n",
    "\n",
    "        for obj_class_with_ext in tqdm(\n",
    "            os.listdir(mask_result_dir / masked_img_name), leave=False\n",
    "        ):\n",
    "            obj_class = obj_class_with_ext.split(\".\")[0]\n",
    "            if obj_class not in objects_to_consider:\n",
    "                continue\n",
    "            obj_mask = (\n",
    "                cv2.imread(\n",
    "                    str(mask_result_dir / masked_img_name / obj_class_with_ext),\n",
    "                    cv2.IMREAD_GRAYSCALE,\n",
    "                )\n",
    "                / 255\n",
    "            )\n",
    "\n",
    "            validated_obj_mask = np.logical_and(obj_mask, validity_map)\n",
    "            gt_dm_masked = gt_dm * validated_obj_mask\n",
    "            if len(np.nonzero(gt_dm_masked)[0]) == 0:\n",
    "                print(f\"No GT depth values for the class: {obj_class}\")\n",
    "                errors_per_class[obj_class][\"imgs_with_no_gt\"].append(img_name)\n",
    "                errors_per_img[img_name][\"masks_with_no_gt\"].append(obj_class)\n",
    "            else:\n",
    "                gt_dm_masked = gt_dm_masked[np.nonzero(gt_dm_masked)]\n",
    "\n",
    "                for model_name, pred_dm in zip(model_names, pred_dms):\n",
    "                    pred_dm_masked = pred_dm * validated_obj_mask\n",
    "                    pred_dm_masked = pred_dm_masked[np.nonzero(pred_dm_masked)]\n",
    "                    mae = eval_utils.mean_abs_err(\n",
    "                        predicted_dm_scaler * pred_dm_masked,\n",
    "                        predicted_dm_scaler * gt_dm_masked,\n",
    "                    )\n",
    "                    rmse = eval_utils.root_mean_sq_err(\n",
    "                        predicted_dm_scaler * pred_dm_masked,\n",
    "                        predicted_dm_scaler * gt_dm_masked,\n",
    "                    )\n",
    "\n",
    "                    if len(np.nonzero(pred_dm_masked)[0]) == 0:\n",
    "                        errors_per_img[img_name][\"masks_with_no_prediction\"][\n",
    "                            model_name\n",
    "                        ].append(obj_class)\n",
    "                        errors_per_class[obj_class][\"imgs_with_no_prediction\"][\n",
    "                            model_name\n",
    "                        ].append(img_name)\n",
    "\n",
    "                    errors_per_class[obj_class][\"metrics\"][\"rmse\"][model_name] += rmse\n",
    "                    errors_per_class[obj_class][\"metrics\"][\"mae\"][model_name] += mae\n",
    "\n",
    "                    errors_per_img[img_name][\"metrics\"][\"rmse\"][model_name] += rmse\n",
    "                    errors_per_img[img_name][\"metrics\"][\"mae\"][model_name] += mae\n",
    "\n",
    "            num_pixels = len(np.nonzero(validated_obj_mask)[0])\n",
    "            pixels_per_class[obj_class] += num_pixels\n",
    "\n",
    "            errors_per_class[obj_class][\"count\"] += 1\n",
    "            errors_per_img[img_name][\"num_objects\"] += 1\n",
    "            errors_per_img[img_name][\"objects\"].append(obj_class)\n",
    "\n",
    "            fig = utils.plot_masked_results_for_all_models(\n",
    "                model_names,\n",
    "                pred_dms,\n",
    "                img,\n",
    "                obj_mask,\n",
    "                obj_class,\n",
    "                title=f\"{obj_class}-{img_name}\",\n",
    "            )\n",
    "            fig_masked = utils.plot_to_image(fig)\n",
    "\n",
    "            figs_masked.append(fig_masked)\n",
    "            fig_classes[obj_class].append(fig_masked)\n",
    "            # break\n",
    "\n",
    "        utils.log_imgs(f\"{img_name}/masked\", figs_masked)\n",
    "        utils.log_imgs(f\"{img_name}/full\", figs_full)\n",
    "        tb_name_prefix = f\"{img_name}\"\n",
    "        utils.log_errors_per_img(errors_per_img, img_name, tb_name_prefix, model_names)\n",
    "\n",
    "        import gc\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        if counter >= n_imgs_to_evaluate:\n",
    "            break\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with class2img_file_writer.as_default():\n",
    "    for obj_class, figs in fig_classes.items():\n",
    "        utils.log_imgs(f\"{obj_class}/imgs\", figs)\n",
    "        utils.log_errors_per_class(errors_per_class, obj_class, model_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kbnet</th>\n",
       "      <th>penet</th>\n",
       "      <th>nlspn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(terrain, 0.4650479342994115)</td>\n",
       "      <td>(terrain, 0.3704181748716596)</td>\n",
       "      <td>(terrain, 0.3146257623304064)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pole, 0.8655391133427363)</td>\n",
       "      <td>(pole, 0.7011595885074903)</td>\n",
       "      <td>(pole, 0.6300329323998113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(road, 0.1497375169594424)</td>\n",
       "      <td>(road, 0.13787451815313678)</td>\n",
       "      <td>(road, 0.13483909598357272)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(bicycle, 0.3197841517881646)</td>\n",
       "      <td>(bicycle, 0.3093299613278094)</td>\n",
       "      <td>(bicycle, 0.26090285530710794)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(person, 0.7971015778479336)</td>\n",
       "      <td>(person, 0.34657245387799596)</td>\n",
       "      <td>(person, 0.26860216249633523)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(rider, 0.5643525372011352)</td>\n",
       "      <td>(rider, 0.4914743114702974)</td>\n",
       "      <td>(rider, 0.4565966829232469)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(vegetation, 0.8304965202911184)</td>\n",
       "      <td>(vegetation, 0.6007383123971879)</td>\n",
       "      <td>(vegetation, 0.5737157495830104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(wall, 0.507303835710187)</td>\n",
       "      <td>(wall, 0.5277456167200104)</td>\n",
       "      <td>(wall, 0.6094227005758003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              kbnet                             penet   \n",
       "0     (terrain, 0.4650479342994115)     (terrain, 0.3704181748716596)  \\\n",
       "1        (pole, 0.8655391133427363)        (pole, 0.7011595885074903)   \n",
       "2        (road, 0.1497375169594424)       (road, 0.13787451815313678)   \n",
       "3     (bicycle, 0.3197841517881646)     (bicycle, 0.3093299613278094)   \n",
       "4      (person, 0.7971015778479336)     (person, 0.34657245387799596)   \n",
       "5       (rider, 0.5643525372011352)       (rider, 0.4914743114702974)   \n",
       "6  (vegetation, 0.8304965202911184)  (vegetation, 0.6007383123971879)   \n",
       "7         (wall, 0.507303835710187)        (wall, 0.5277456167200104)   \n",
       "\n",
       "                              nlspn  \n",
       "0     (terrain, 0.3146257623304064)  \n",
       "1        (pole, 0.6300329323998113)  \n",
       "2       (road, 0.13483909598357272)  \n",
       "3    (bicycle, 0.26090285530710794)  \n",
       "4     (person, 0.26860216249633523)  \n",
       "5       (rider, 0.4565966829232469)  \n",
       "6  (vegetation, 0.5737157495830104)  \n",
       "7        (wall, 0.6094227005758003)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mae_per_category = {}\n",
    "model_mae_per_category_unsorted = {}\n",
    "for model_name in model_names:\n",
    "    model_errors = {}\n",
    "    for cat, cat_stats in errors_per_class.items():\n",
    "        model_errors[cat] = (\n",
    "            cat_stats[\"metrics\"][\"mae\"][model_name]\n",
    "        ) / cat_stats[\"count\"]\n",
    "    model_mae_per_category[model_name] = sorted(\n",
    "        model_errors.items(), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    model_mae_per_category_unsorted[model_name] = model_errors.items()\n",
    "pd.DataFrame(model_mae_per_category_unsorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_mae_per_category).to_csv(\"model_mae_per_category.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for writer in [img2class_file_writer, class2img_file_writer]:\n",
    "    with writer.as_default():\n",
    "        for model_name in model_names:\n",
    "            model_config = yaml.safe_load(open(f\"{model_name}_val.yaml\"))\n",
    "            path_to_result_dir = model_config[\"result_dir\"]\n",
    "            tf.summary.text(\n",
    "                f\"meta/{model_name}/result_dir\",\n",
    "                str(path_to_result_dir),\n",
    "                step=0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad1db80ca9b36dd5ac1f394e7b9b19f6166d1645d5a0e339bf524a97ebc784e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
