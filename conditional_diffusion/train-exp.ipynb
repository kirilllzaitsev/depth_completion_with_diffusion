{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import comet_ml\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from load_data import load_data\n",
    "from model import init_model\n",
    "from rsl_depth_completion.conditional_diffusion.config import cfg as cfg_cls\n",
    "from rsl_depth_completion.conditional_diffusion.custom_trainer import ImagenTrainer\n",
    "from rsl_depth_completion.conditional_diffusion.utils import (\n",
    "    dict2mdtable,\n",
    "    log_params_to_exp,\n",
    ")\n",
    "from rsl_depth_completion.diffusion.utils import set_seed\n",
    "from rsl_depth_completion.conditional_diffusion.pipeline_utils import (\n",
    "    get_ds_kwargs,\n",
    "    setup_train_pipeline,\n",
    ")\n",
    "from rsl_depth_completion.conditional_diffusion.data_utils import (\n",
    "    update_eval_batch_file,\n",
    "    fill_eval_batch_with_coco,\n",
    ")\n",
    "\n",
    "from rsl_depth_completion.conditional_diffusion.pipeline_utils import create_tracking_exp\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "logdir_name = \"debug\"\n",
    "\n",
    "out_dir = f\"/tmp/{logdir_name}\" \n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "# logdir_name = \"standalone_trainer\"\n",
    "cfg, train_logdir = setup_train_pipeline(logdir_name, use_ssl=False)\n",
    "cfg.disabled = True\n",
    "cfg.input_res = 128\n",
    "cfg.unets_output_res = [64,128]\n",
    "cfg.use_triplet_loss=False\n",
    "\n",
    "experiment = create_tracking_exp(cfg)\n",
    "\n",
    "ds_kwargs = get_ds_kwargs(cfg)\n",
    "\n",
    "ds, train_dataloader, val_dataloader = load_data(\n",
    "    ds_name=cfg.ds_name, do_overfit=cfg.do_overfit, cfg=cfg, **ds_kwargs\n",
    ")\n",
    "x=ds[0]\n",
    "eval_batch = ds.eval_batch\n",
    "batch=next(iter(train_dataloader))\n",
    "# eval_batch = torch.utils.data.default_collate([ds[210],ds[40]])\n",
    "# eval_batch = {k:v[:cfg.batch_size] for k,v in torch.load(\"eval_batch_rand_sdm.pt\")[cfg.input_res].items()}\n",
    "\n",
    "print(x['cond_img'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([256, 64, 128, 160])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"eval_batch.pt\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base dimension of your u-net should ideally be no smaller than 128, as recommended by a professional DDPM trainer https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/\n"
     ]
    }
   ],
   "source": [
    "cfg.use_super_res = True\n",
    "unets, model = init_model(experiment, ds_kwargs, cfg) \n",
    "trainer_kwargs = dict(\n",
    "    imagen=model,\n",
    "    use_lion=False,\n",
    "    lr=0.5,\n",
    "    max_grad_norm=1.0,\n",
    "    fp16=cfg.fp16,\n",
    "    use_ema=False,\n",
    "    accelerate_log_with=\"comet_ml\",\n",
    "    accelerate_project_dir=\"logs\",\n",
    ")\n",
    "trainer = ImagenTrainer(**trainer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet 1\tloss: 0.6485889703035355\n",
      "unet 1\tloss: 32.736530780792236\n",
      "unet 1\tloss: 68.83356475830078\n",
      "unet 1\tloss: 24.02565371990204\n",
      "checkpoint saved to /tmp/debug/checkpoint_1.pt\n",
      "unet 2\tloss: 1.0122721195220947\n",
      "unet 2\tloss: 25.605119466781616\n",
      "unet 2\tloss: 52.253578186035156\n",
      "unet 2\tloss: 65.95992279052734\n",
      "checkpoint saved to /tmp/debug/checkpoint_2.pt\n"
     ]
    }
   ],
   "source": [
    "if cfg.do_overfit:\n",
    "    batch = eval_batch\n",
    "is_multi_unet_training = (trainer.num_unets) > 1\n",
    "images = batch[\"input_img\"]\n",
    "if \"text_embed\" in batch:\n",
    "    text_embeds = batch[\"text_embed\"]\n",
    "else:\n",
    "    text_embeds = None\n",
    "if \"cond_img\" in batch:\n",
    "    cond_images = batch[\"cond_img\"]\n",
    "else:\n",
    "    cond_images = None\n",
    "\n",
    "validity_map_depth = torch.where(\n",
    "    batch[\"sdm\"] > 0, torch.ones_like(batch[\"sdm\"]), batch[\"sdm\"]\n",
    ").bool()\n",
    "\n",
    "def step_unet_i(images, text_embeds, cond_images, validity_map_depth, i, trainer):\n",
    "    loss = trainer(\n",
    "            images=images,\n",
    "            text_embeds=text_embeds,\n",
    "            cond_images=cond_images,\n",
    "            unet_number=i,\n",
    "            max_batch_size=cfg.max_batch_size,\n",
    "            validity_map_depth=validity_map_depth\n",
    "            if i == (trainer.num_unets) and cfg.use_validity_map_depth\n",
    "            else None,\n",
    "        )\n",
    "    trainer.update(unet_number=i)\n",
    "    return loss\n",
    "\n",
    "i=1\n",
    "trainer = ImagenTrainer(**trainer_kwargs)\n",
    "for epoch in range(1, 5):\n",
    "    loss = step_unet_i(images, text_embeds, cond_images, validity_map_depth, i, trainer)\n",
    "    print(f\"unet {i}\\tloss: {loss}\")\n",
    "ckpt_path1 = f\"{out_dir}/checkpoint_{i}.pt\"\n",
    "trainer.save(ckpt_path1)\n",
    "\n",
    "i=2\n",
    "trainer = ImagenTrainer(**trainer_kwargs)\n",
    "for epoch in range(1, 5):\n",
    "    loss = step_unet_i(images, text_embeds, cond_images, validity_map_depth, i, trainer)\n",
    "    print(f\"unet {i}\\tloss: {loss}\")\n",
    "\n",
    "ckpt_path2 = f\"{out_dir}/checkpoint_{i}.pt\"\n",
    "trainer.save(ckpt_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensure unet 1 is trained. this trainer instance hasn't trained it\n",
      "when sampling, you can pass stop_at_unet_number to stop early in the cascade, so it does not try to generate with untrained unets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2247cfcab878408d8a843497bddea7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ffc47519b249baad2a44f3f64c6199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rsl_depth_completion.conditional_diffusion.train_imagen_loop import sample\n",
    "samples_lowres = sample(\n",
    "                        cfg,\n",
    "                    trainer,\n",
    "                    experiment,\n",
    "                    out_dir,\n",
    "                    eval_batch,\n",
    "                    1,\n",
    "                    start_at_unet_number=1,\n",
    "                    start_image_or_video=None,\n",
    "                    stop_at_unet_number=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensure unet 1 is trained. this trainer instance hasn't trained it\n",
      "when sampling, you can pass stop_at_unet_number to stop early in the cascade, so it does not try to generate with untrained unets\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f0f952fe5e4c37a1e4b9b7b0358da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6436bd2b5bb7421791d0b4769b4c5692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_sr_256 = sample(\n",
    "                        cfg,\n",
    "                    trainer,\n",
    "                    experiment,\n",
    "                    out_dir,\n",
    "                    eval_batch,\n",
    "                    2,\n",
    "                    start_at_unet_number=2,\n",
    "                    start_image_or_video=samples_lowres[0],\n",
    "                    stop_at_unet_number=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 64, 64]), torch.Size([2, 1, 128, 128]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_lowres[0].shape, samples_sr_256[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
